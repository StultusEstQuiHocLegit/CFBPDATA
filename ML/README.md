# Machine Learning Application (Regression)

This subproject hosts a self-contained PHP application for training and serving bankruptcy probability models on top of the CSV exports generated by the data collectors in the repository root. It exposes an interactive browser UI that allows merging corresponding datasets, training a logistic regression model and inspecting metrics (and also scoring new company financials).

## Directory overview

```
ML/
├─ README.md
├─ autoload.php
├─ composer.json
├─ composer.lock
├─ config/
│  ├─ default.json
│  └─ features.json
├─ data/
│  └─ raw/
│     ├─ financials.csv
│     └─ financials_solvent.csv
├─ models/
│  ├─ calibrator.bin
│  ├─ metadata.json
│  ├─ model.bin
│  ├─ preprocessor.bin
│  ├─ preprocessor.bin.step0
│  ├─ preprocessor.bin.step1
│  ├─ preprocessor.bin.step2
│  └─ preprocessor.bin.step3
├─ public/
│  ├─ assets/
│  │  ├─ app.css
│  │  └─ app.js
│  └─ index.php
├─ reports/
│  └─ metrics.json
├─ sample_input.csv
├─ sample_input_full.csv
├─ src/
│  ├─ Config/
│  │  └─ Config.php
│  ├─ Data/
│  │  ├─ DataFrame.php
│  │  └─ Splitter.php
│  ├─ Features/
│  │  ├─ FeatureBuilder.php
│  │  ├─ Transformer.php
│  │  └─ Transformers/
│  │     ├─ Imputer.php
│  │     ├─ OneHotEncoder.php
│  │     ├─ Preprocessor.php
│  │     ├─ RobustScaler.php
│  │     └─ Winsorizer.php
│  ├─ Http/
│  │  ├─ Controllers/
│  │  │  ├─ PredictController.php
│  │  │  └─ TrainController.php
│  │  └─ Responses/
│  │     └─ Json.php
│  ├─ IO/
│  │  └─ CSVReader.php
│  ├─ ML/
│  │  ├─ Calibrator/
│  │  │  ├─ Beta.php
│  │  │  ├─ Isotonic.php
│  │  │  └─ Platt.php
│  │  ├─ EstimatorInterface.php
│  │  ├─ Eval/
│  │  │  ├─ Metrics.php
│  │  │  └─ Thresholds.php
│  │  ├─ Models/
│  │  │  ├─ GradientBoosting.php
│  │  │  ├─ LogisticRegression.php
│  │  │  └─ RandomForest.php
│  │  └─ Training/
│  │     └─ Trainer.php
│  ├─ Persistence/
│  │  └─ ModelStore.php
│  └─ Util/
│     └─ Logger.php
└─ tests/
   ├─ Data/
   │  └─ DataFrameTest.php
   ├─ Features/
   │  ├─ FeatureBuilderExtraTest.php
   │  ├─ FeatureBuilderTest.php
   │  └─ Transformers/
   │     ├─ RobustScalerTest.php
   │     └─ WinsorizerTest.php
   └─ ML/
      ├─ Calibrator/
      │  └─ BetaCalibratorTest.php
      ├─ Eval/
      │  └─ ThresholdsTest.php
      └─ Models/
         └─ LogisticRegressionTest.php
```

### Root files

* `autoload.php`: Lightweight PSR-4 autoloader so the application can be run without installing composer dependencies. It maps the `App\` namespace directly onto `src/`.
* `composer.json`: Documents the runtime requirement on PHP 8+, wires PHPUnit as the only dev dependency and mirrors the PSR-4 namespace mapping for the case where the project is installed with composer tooling.
* `sample_input.csv` / `sample_input_full.csv`: Ready-to-use files for exercising the prediction endpoint, the short version contains a handful of rows, whereas the "full" file includes every feature column expected by the pipeline so the complete scoring flow can be validated.

### Configuration (`config/`)

* `default.json`: Centralises operational settings for the training controller. Alongside the data paths, schema hints and temporal cut-offs it exposes **three estimator families**: `logistic_regression`, `random_forest` and `gradient_boosting`, each with their own hyperparameter grids. Logistic regression keeps the familiar L2 sweep (with automatic relaxation when the validation scores collapse into too few bins), while the new tree ensembles surface tree counts, depth limits, feature subsampling and learning rates so non-linear capacity can be dialled in without editing the core code. The optional `cross_validation` block enables grouped rolling-origin folds before the final fit and the `calibration` key accepts `isotonic`, `platt` *or* the new `beta` calibrator (whose learning-rate/iteration knobs live under `beta`). Threshold selection remains driven by `thresholds.optimize_for`, but can weigh asymmetric costs or target F‑beta in addition to PR-AUC/F1.
* `features.json`: Declares the curated feature manifest consumed by the builder. Beyond the legacy liquidity/leverage triplet from former iterations, the ratio roster includes **net margin**, **asset and inventory turnover**, **cash ratio**, **operating margin** and **debt-to-equity** so profitability, efficiency and capital structure are all represented. The `extra_features` section retains Altman-style leverage, coverage, working-capital and cash-flow diagnostics and adds operational clocks such as `DaysAR`, `DaysINV`, `DaysAP` and the `CashConversionCycle`, plus accrual quality and capital-structure event flags (`DividendOmission`, `DebtIssuanceSpike`, `DebtRepaymentSpike`). For every ratio or extra declared, matching trend (`*_tren`) and rolling-volatility (`*_vola`) series are generated automatically and interaction terms such as `leverage_profitability`, `liquidity_cashflow`, `size_profitability`, `leverage_margin` and `liquidity_accruals` capture first-order cross-effects. All derived columns are clipped to conservative domain bounds (for example net margin and ROA within ±1, turnover ratios up to 5, debt-to-equity capped at 10, volatility ≤ 2) before scaling to keep the robust scaler stable in the face of outliers.

The most important engineered signals and their meanings are:

| Feature | Formula | Economic rationale |
| --- | --- | --- |
| `net_margin` | `NetIncomeLoss ÷ SalesRevenueNet` | captures bottom-line profitability, persistently negative margins highlight distressed operations |
| `operating_margin` | `OperatingIncomeLoss ÷ SalesRevenueNet` | focuses on core business profitability before financing/tax noise |
| `asset_turnover` | `SalesRevenueNet ÷ TotalAssets` | measures efficiency in deploying assets to generate revenue |
| `inventory_turnover` | `CostOfGoodsSold ÷ InventoryNet` | indicates working-capital discipline, low turns can signal demand or supply chain issues |
| `cash_ratio` | `CashAndCashEquivalentsAtCarryingValue ÷ CurrentLiabilities` | conservative liquidity gauge showing the ability to meet short-term obligations with cash alone |
| `debt_to_equity` | `TotalLiabilities ÷ (TotalAssets − TotalLiabilities)` | tracks leverage borne by equity holders, rapid spikes often precede restructurings |
| `TL_TA` | `TotalLiabilities ÷ TotalAssets` | core leverage indicator used in Altman-style scores |
| `Debt_Assets` | `LongTermDebtNoncurrent ÷ TotalAssets` | highlights structural debt burden relative to the balance sheet |
| `WC_TA` | `(CurrentAssets − CurrentLiabilities) ÷ TotalAssets` | working-capital adequacy relative to total resources |
| `EBIT_InterestExpense` | `OperatingIncomeLoss ÷ InterestExpense` | traditional coverage ratio to detect inability to service debt |
| `EBITDA_InterestExpense` | `(OperatingIncomeLoss + DepreciationAndAmortization) ÷ InterestExpense` | softer coverage test that factors in non-cash expenses |
| `CFO_Liabilities` | `NetCashProvidedByUsedInOperatingActivities ÷ TotalLiabilities` | tests whether operating cash can support the liability stack |
| `CFO_DebtService` | `NetCashProvidedByUsedInOperatingActivities ÷ (ProceedsFromIssuanceOfDebt + RepaymentsOfDebt)` | flags when debt cash flows exceed operating cash generation |
| `ROA` | `NetIncomeLoss ÷ TotalAssets` | asset-level profitability benchmark |
| `OperatingMargin` | duplicate exposure retained for backwards compatibility with existing reports |
| `DaysAR` | `365 x AccountsReceivableNetCurrent ÷ SalesRevenueNet` | days sales outstanding, rising values can warn of collection issues |
| `DaysINV` | `365 x InventoryNet ÷ CostOfGoodsSold` | inventory days on hand, ballooning stock often precedes write-downs |
| `DaysAP` | `365 x AccountsPayableCurrent ÷ CostOfGoodsSold` | payment cycle length, sharp drops may reflect suppliers tightening terms |
| `CashConversionCycle` | `DaysAR + DaysINV − DaysAP` | end-to-end cash cycle summarising working-capital health |
| `DividendOmission` | indicator from `PaymentsOfDividends` that flags suspended payouts |
| `DebtIssuanceSpike` | indicator built from year-over-year jumps in `ProceedsFromIssuanceOfDebt` |
| `DebtRepaymentSpike` | indicator signalling unusually large repayments |
| `Accruals` | `(NetIncomeLoss − NetCashProvidedByUsedInOperatingActivities) ÷ TotalAssets` | measures earnings quality, high accruals can mask cash shortfalls |
| `<feature>_tren` | year-over-year delta for each feature above | captures direction of change to detect accelerating deterioration or recovery |
| `<feature>_vola` | rolling three-year standard deviation for each feature above | quantifies instability, volatile fundamentals often precede default |
| Interaction terms | products of complementary metrics (for example: `debt_to_equity x net_margin`) | allow the model to capture compounding risk effects without hand-written rules |

Switching between learners can be done by changing `model.type` in `default.json`. For example, setting it to `gradient_boosting` to enable the depth-configurable tree ensemble and adjusting `gradient_boosting.num_trees_grid` / `learning_rate_grid` accordingly or leaving it on `logistic_regression` with a custom `l2_grid`. When `cross_validation.enabled` is true the trainer evaluates every combination from these grids using the specified `cross_validation.metric` (either `pr_auc` or `roc_auc`) before fitting the final model and the selected values are emitted in `reports/metrics.json` under the `hyperparameters` key along with the per-fold scores and the number of temporal folds considered.

### Data (`data/`)

* `data/raw/financials.csv`: Historical filings for companies that ultimately filed for bankruptcy, each record represents a company-year observation used as positive-class examples during training.
* `data/raw/financials_solvent.csv`: Matching solvent cohort that supplies the negative class, during training the pipeline connects the two sources, derives the label column and performs temporal splits to respect company-level leakage constraints.

### Public web assets (`public/`)

* `public/index.php`: Single entry point for both the interactive dashboard and AJAX connection. It routes POST requests to the training and prediction controllers, handles error reporting and renders the HTML for the UI cards ("Train Model", "Model", "Predict", "Log Console" and "Results").
* `public/assets/app.css`: Styling for the dashboard cards, buttons and result tables.
* `public/assets/app.js`: JS controller that submits the forms via `fetch`, streams log messages to the on-page console and renders metrics or prediction tables corresponding to the backend responses.

### Source code (`src/`)

* `Config/Config.php`: Structure for loading JSON configuration files, exposing nested keys as read-only properties with early validation for missing entries.
* `Data/DataFrame.php`: Immutable, columnar data structure with helpers for selecting rows/columns, connecting frames and extracting label vectors. It serves as the in-memory substrate for the rest of the pipeline.
* `Data/Splitter.php`: Builds deterministic train/validation/test splits grouped by company and year so temporal leakage is prevented.
* `Features/FeatureBuilder.php`: Orchestrates the feature engineering process by reading `features.json`, deriving ratios/aggregates and wiring transformation steps.
* `Features/Transformer.php`: Base contract for preprocessors, concrete implementations live under `Features/Transformers/`:
  * `Imputer.php`: Fills missing values using the configured strategy (median by default).
  * `OneHotEncoder.php`: Expands categorical features into binary indicator columns.
  * `Preprocessor.php`: Composite step that chains winsorisation, scaling and encoding while recording fitted parameters for reuse during prediction.
  * `RobustScaler.php`: Scales numeric columns using median/IQR statistics to dampen outliers.
  * `Winsorizer.php`: Clamps the extremes of numeric distributions according to the configured percentiles.
* `Http/Controllers/TrainController.php`: Handles the "train"-POST, loading raw CSVs, merging cohorts, invoking feature engineering, training models and returning metrics plus log output to the browser console.
* `Http/Controllers/PredictController.php`: Responds to uploaded CSVs by loading the persisted preprocessing pipeline and model, scoring each row and packaging probabilities, risk buckets and top-contributing features.
* `Http/Responses/Json.php`: Tiny helper that standardises JSON payload format (`status`, `data`, `message`) for front-end consumption.
* `IO/CSVReader.php`: Streaming CSV loader that normalises headers and casts values for the DataFrame abstraction.
* `ML/Models/LogisticRegression.php`, `ML/Models/RandomForest.php` and `ML/Models/GradientBoosting.php`: The logistic regression remains the linear baseline with L2 regularisation, the random forest is a bagging ensemble with bootstrap sampling and random feature subsampling, gradient boosting trains depth-configurable regression trees that sequentially correct residuals.
* `ML/Training/Trainer.php`: End-to-end coordinator that fits the chosen model with class weighting, runs calibration, computes evaluation metrics and calls into the persistence layer for saving artefacts.
* `ML/Calibrator/Isotonic.php`, `ML/Calibrator/Platt.php` and `ML/Calibrator/Beta.php`: Offer non-parametric, logistic and three-parameter beta calibration respectively so probability outputs can match observed bankruptcy rates even with asymmetric score distributions.
* `ML/Eval/Metrics.php` and `ML/Eval/Thresholds.php`: Calculate PR/ROC AUC, Brier score and derive operating thresholds such as balanced F1 and minimum recall cut-offs.
* `Persistence/ModelStore.php`: Saves/loads serialised models, preprocessors, metrics and thresholds to the `models/` and `reports/` directories so future sessions can reuse the artefacts without retraining.
* `Util/Logger.php`: Appends timestamped messages to an in-memory buffer that streams back to the UI, giving real-time visibility into each pipeline step.

## Runtime artefacts

Training writes calibrated model weights, scaler parameters and evaluation summaries back into `models/` and `reports/`, alongside JSON snapshots of decision thresholds. The metrics report also records the actually selected `selected_l2` (or `num_trees`/`learning_rate`/`max_depth` for gradient boosting), plus reliability curves for validation and test folds so calibration can be audited after the fact. These persisted assets are what the prediction flow reloads so the experience remains stateful across browser sessions.

## How to run

The simplest approach is to upload the whole repository to a web server using `FTP` and then access `https://www.SOMEPLACEHOLDERFORTHESERVERNAME.com/ML/public/index.php` (replacing `SOMEPLACEHOLDERFORTHESERVERNAME` with the actual server name) in the browser.

Alternatively, `XAMPP` or similar programs can be used. The application is a plain PHP front end backed by filesystem storage. No composer installation or external services are required, everything needed ships with this folder. Simply start PHP's built-in web server from the repository root (or any location) and point it at `ML/public/index.php`:

```bash
php -S localhost:8000 -t ML/public/
```

Then `http://localhost:8000/` has to be opened in the browser, the single page app served from `public/index.php` will load and then the UI can be used.

## Training workflow

1. **Configuration is loaded and validated**: Pressing **Train** triggers the `TrainController`, which first pulls `config/default.json` and `config/features.json` through `Config/Config.php`. Required paths, temporal split definitions and preprocessing hyperparameters are sanity checked so that any missing keys abort immediately with a descriptive log message rather than failing deeper in the pipeline.
2. **Source files are streamed into DataFrames**: `IO/CSVReader.php` reads `data/raw/financials.csv` (bankrupt cohort) and `data/raw/financials_solvent.csv` (solvent cohort) in a streaming fashion to avoid excessive memory overhead. Headers are normalised, numeric fields are cast and each file is turned into an immutable `Data/DataFrame.php` instance.
3. **Label engineering joins the cohorts**: `Data/DataFrame::concat` stitches the two cohorts together, stamping a `label` column that marks the last available fiscal year before bankruptcy as `1` and solvent observations as `0`. Company identifiers and year columns are harmonised so the later splitting logic can operate deterministically.
4. **Temporal and entity filters are applied**: Before feature construction, optional filters declared in the configuration (such as restricting to filings newer than a cutoff year or removing entities with too few observations (fewer than 3)) are applied. This keeps evaluation folds aligned with the business scenario the model emulates.
5. **Feature manifests are interpreted**: `Features/FeatureBuilder.php` reads `config/features.json`, derives the extended ratio deck (liquidity, leverage, profitability, efficiency and cash-generation), attaches log-size and the distress scores and automatically appends the requested year-over-year trends and rolling three-year volatilities. Interaction terms such as leverage x profitability or liquidity x accruals are built on the fly and every raw, trend and volatility series is clipped to the documented domain bounds (for example net margin in ±1, debt-to-equity ≤ 10, volatility ≤ 2) before the preprocessing stack ever sees them.
6. **Transformers are fit on the training subset**: For each configured feature, a pipeline of transformer classes (`Winsorizer`, `Imputer`, `RobustScaler`, `OneHotEncoder`) is assembled. The transformers learn their parameters (percentile caps, medians, scale factors, category vocabularies) only from the training portion to prevent leakage.
7. **Dataset splitting respects companies and chronology**: `Data/Splitter.php` partitions the data into train, validation and test folds while ensuring all records for a given company-year bucket stay together. The split boundaries follow the temporal windows defined in `config/default.json`, meaning the validation set emulates "future" periods relative to training data.
8. **Pipelines transform every fold**: Once fitted, the composite preprocessor (`Features/Transformers/Preprocessor.php`) is executed on the train, validation and test sets. Numeric columns are winsorised, scaled and imputed, categoricals become binary indicators. Intermediate states are serialised so that the same operations can later be replayed at prediction time.
9. **Model fitting incorporates class imbalance handling**: `ML/Training/Trainer.php` instantiates the configured estimator with inverse-frequency weights. Logistic regression still supports the adaptive L2 sweep and unique-probability safeguards, while setting `model.type` to `random_forest` or `gradient_boosting` triggers genuine bagged trees / depth-configurable gradient boosting. When `cross_validation.enabled` is true the trainer first evaluates each hyperparameter combination across rolling temporal folds, reports the per-fold metric and then retrains on the full pre-test window with the winning parameters.
10. **Probability calibration refines scores**: Raw validation scores feed into `ML/Calibrator/Isotonic.php`, `ML/Calibrator/Platt.php` or the parametric `ML/Calibrator/Beta.php`, depending on the configuration toggle. Isotonic regression remains the non-parametric main-worker, Platt scaling offers fast logistic re-fitting and the beta calibrator learns asymmetric S-shaped mappings via gradient descent. All three clamp inputs and deduplicate flat regions so the resulting probabilities line up with observed bankruptcy rates, a prerequisite for trustworthy thresholding.
11. **Evaluation spans metrics, reliability curves and multiple operating thresholds**: `ML/Eval/Metrics.php` computes area-under-curve scores, log-loss and Brier score across validation and test folds and also buckets probabilities into deciles so calibration reliability plots can be rendered. `ML/Eval/Thresholds.php` sweeps the unique probability grid for operating points, returning the primary cut-off aligned with the chosen optimisation objective (PR-AUC, cost, F-beta or F1), the highest-recall option that satisfies the configured constraint (for example 80 % recall) and their associated confusion matrices on validation and test data. Expected cost and F-beta values are carried through into `reports/metrics.json` alongside the threshold values so downstream dashboards can reason about trade-offs explicitly.
12. **Artefacts are persisted for reuse**: `Persistence/ModelStore.php` writes the trained model weights, the fitted preprocessing pipeline (including staged versions in `preprocessor.bin.step*`), calibration mapping, metrics summary and chosen thresholds into `models/` and `reports/`. Subsequent training or prediction sessions load these artefacts to skip redundant work and guarantee consistent behaviour.

Each of the above steps logs status updates that appear live in the UI's console pane, making it easy to trace progress and troubleshoot data issues. Because all artefacts (model coefficients, scaler parameters, thresholds, metrics) are saved alongside the raw inputs, future prediction sessions or retraining runs can pick up exactly where the previous training left off without manual intervention.

## Model selection and tuning

Three estimator families are available in the subfolders codebase:

* **Logistic regression**: Fast, interpretable coefficients with L2 regularisation still tuned via `model.logistic_regression.l2_grid`. It excels when decision boundaries are close to linear and feature contributions are needed.
* **Random forest**: A bagging ensemble of decision trees that samples both observations and features at each split. It improves ROC-/PR-AUC on non-linear interactions at the cost of longer training time and larger persisted models.
* **Gradient boosting**: Depth-configurable regression trees fitted sequentially with learning-rate shrinkage. It offers the highest capacity but is more sensitive to hyperparameters.

All three respect the `cross_validation` block when enabled. For example, to sweep forest depth and tree counts with temporal folds:

```json
{
  "model": {
    "type": "random_forest",
    "random_forest": {
      "num_trees": 100,
      "num_trees_grid": [50, 100, 200],
      "max_depth": 5,
      "max_depth_grid": [3, 5, 7],
      "feature_fraction": 0.8
    }
  },
  "cross_validation": {
    "enabled": true,
    "num_folds": 3,
    "metric": "pr_auc"
  }
}
```

The trainer reports the winning setting (`selected_num_trees`, `selected_max_depth`, `selected_learning_rate`, ...) and the per-fold metric trail in `reports/metrics.json` so run can be compared.

## Temporal cross-validation

`Data/Splitter::temporalFolds` constructs rolling origin folds that always train on historical years and validate on the next year while keeping company IDs intact. When `cross_validation.enabled` is `true`, `Trainer::crossValidateAndTrain` evaluates every hyperparameter combination on these folds, averages the requested metric (`pr_auc` by default, `roc_auc` when demanded) and only then fits the final model on the union of all pre-test data. This guards against optimistic single-year splits and makes sure selected parameters generalise to future filing seasons. Disabling the block falls back to the legacy single validation year workflow for quicker experiments.

## Probability calibration options

After the best estimator is chosen, the trainer calibrates raw probabilities using the method specified under `calibration`:

* `isotonic`: Non-parametric monotonic fit that excels with plenty of validation data but can overfit small samples.
* `platt`: Logistic regression on top of the scores, lightweight and stable for moderate datasets.
* `beta`: Newly added three-parameter mapping optimised via gradient descent that captures asymmetric S-shaped reliability curves.

Custom learning-rate / iteration settings for beta calibration live under the optional `beta` block. Regardless of the choice, calibrated probabilities feed into all downstream metrics and are persisted alongside the model for consistent scoring.

## Threshold optimisation

`ML/Eval/Thresholds.php` supports multiple optimisation criteria:

* `pr_auc` / `f1`: Legacy behaviour optimising PR-AUC or F1 directly.
* `cost`: Minimises `expected_cost = cost_false_positive x FP + cost_false_negative x FN`, ideal when quantifying asymmetric penalties (for example: false negatives being five times worse) is needed.
* `f_beta`: Maximises the general F-β score where `β>1` emphasises recall and `β<1` emphasises precision.

Each sweep records the chosen cut-offs, expected cost or F-β score and the supporting confusion matrices in `reports/metrics.json`. Secondary thresholds such as the minimum recall operating point remain available and also include the enriched metrics for dashboards.

## Scoring new companies

Use the **Predict** panel in the UI to upload a CSV that follows the same schema as the raw training files. The server reuses the stored preprocessor and model to output:

* Calibrated bankruptcy probabilities for each row.
* Risk buckets (High risk, Monitor, Low risk) derived from the learned thresholds.
* Per-feature contributions for logistic regression models, highlighting the ratios that drive the prediction.

Example input files `sample_input.csv` (short) and `sample_input_full.csv` (full schema) are bundled in the project root and can be used to verify end-to-end behaviour.


